{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Task 1, collect reviews data from personal website address:\n",
    "\n",
    "http://mlg.ucd.ie/modules/python/assign2/20210711/\n",
    "\n",
    "extract the following information:\n",
    "- The star rating of the review\n",
    "- The title text of the review\n",
    "- The main body text of the review\n",
    "- Review helpfulness information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using beautiful soup to collect all URL of each month's total review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first page of comments contains link to reviews of each month. There are more than one page of comments per month. We need to access the next page recursively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numbers of links in first level page:  72\n",
      "The head of links: \n",
      "http://mlg.ucd.ie/modules/python/assign2/20210711/reviews-2016-jan-01.html\n",
      "http://mlg.ucd.ie/modules/python/assign2/20210711/reviews-2016-feb-01.html\n",
      "http://mlg.ucd.ie/modules/python/assign2/20210711/reviews-2016-mar-01.html\n",
      "http://mlg.ucd.ie/modules/python/assign2/20210711/reviews-2016-apr-01.html\n",
      "http://mlg.ucd.ie/modules/python/assign2/20210711/reviews-2016-may-01.html\n"
     ]
    }
   ],
   "source": [
    "#Find the first level Web page through the URL\n",
    "base_url = \"http://mlg.ucd.ie/modules/python/assign2/20210711/\"\n",
    "html = urlopen(base_url).read().decode('utf-8')\n",
    "# load the beautiful soup\n",
    "soup = BeautifulSoup(html, features='lxml')\n",
    "# capture the first page URL suffix of each month, located by class id and class name\n",
    "href_class = soup.find_all(\"a\", {\"class\": \"list-group-item list-group-item-action\"})\n",
    "href_suffix = [suffix[\"href\"] for suffix in href_class]\n",
    "\n",
    "first_herf = [(base_url + suffix) for suffix in href_suffix]\n",
    "\n",
    "print('numbers of links in first level page: ', len(first_herf))\n",
    "print('The head of links: ')\n",
    "for x in range(5):\n",
    "    print (first_herf[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, find the URLs of each secondary page per month except the first page through the URLs we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numbers of all review pages link:  344\n",
      "The head of links: \n",
      "http://mlg.ucd.ie/modules/python/assign2/20210711/reviews-2016-jan-01.html\n",
      "http://mlg.ucd.ie/modules/python/assign2/20210711/reviews-2016-feb-01.html\n",
      "http://mlg.ucd.ie/modules/python/assign2/20210711/reviews-2016-mar-01.html\n",
      "http://mlg.ucd.ie/modules/python/assign2/20210711/reviews-2016-apr-01.html\n",
      "http://mlg.ucd.ie/modules/python/assign2/20210711/reviews-2016-may-01.html\n"
     ]
    }
   ],
   "source": [
    "# More than one page of comments every month. \n",
    "#For example, there are five pages of comments in the first month of 2016\n",
    "total_herf = [i for i in first_herf]\n",
    "for link in total_herf:\n",
    "    next_page_url = link\n",
    "    html = urlopen(next_page_url).read().decode('utf-8')\n",
    "    soup = BeautifulSoup(html, features='lxml')\n",
    "    href_class = soup.find_all(\"a\", {\"class\": \"page-link\", \"href\": re.compile('.*?\\.html'),  \"aria-label\": \"Next\"})\n",
    "    # herf_suffix would be a list with only one element\n",
    "    href_suffix = [suffix[\"href\"] for suffix in href_class]\n",
    "    if(len(href_suffix)): #judge if next link is available\n",
    "        link = base_url + href_suffix.pop()\n",
    "        # no need to judge if duplicate\n",
    "        total_herf.append(link)\n",
    "    \n",
    "print('numbers of all review pages link: ', len(total_herf))\n",
    "print('The head of links: ')\n",
    "for x in range(5):\n",
    "    print (total_herf[x])\n",
    "#print('\\n', new_href)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dump the url for further use possibly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"review_url.txt\", \"w\") as outfile:\n",
    "    outfile.write(\"\\n\".join(str(item) for item in total_herf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the file as list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "344\n",
      "http://mlg.ucd.ie/modules/python/assign2/20210711/reviews-2016-jan-01.html\n",
      "http://mlg.ucd.ie/modules/python/assign2/20210711/reviews-2016-feb-01.html\n",
      "http://mlg.ucd.ie/modules/python/assign2/20210711/reviews-2016-mar-01.html\n",
      "http://mlg.ucd.ie/modules/python/assign2/20210711/reviews-2016-apr-01.html\n",
      "http://mlg.ucd.ie/modules/python/assign2/20210711/reviews-2016-may-01.html\n"
     ]
    }
   ],
   "source": [
    "with open(\"review_url.txt\") as file:\n",
    "    lines = file.readlines()\n",
    "    lines = [line.rstrip() for line in lines]\n",
    "\n",
    "print(len(lines))\n",
    "for x in range(5):\n",
    "    print (lines[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the list of URLs above, parse every review in 2016-2021. For each review, extract the following information: i) The star rating of the review ii) The title text of the review iii) The main body text of the review iv) Review helpfulness information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>rating</th>\n",
       "      <th>helpful_user_num</th>\n",
       "      <th>total_user_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The herbs were great...but the cherry tomatoes...</td>\n",
       "      <td>The herb kit that came with my Aerogarden was ...</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Even more useful than regular parchment paper</td>\n",
       "      <td>I originally bought this just because it was c...</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shake it before you bake it</td>\n",
       "      <td>If you do it in reverse (bake before shaking),...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not what the picture describes</td>\n",
       "      <td>I bought this steak for my father in law for C...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What a ripe off - GIVE ME A BREAK</td>\n",
       "      <td>Sorry but I had these noodles and they are no ...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  The herbs were great...but the cherry tomatoes...   \n",
       "1      Even more useful than regular parchment paper   \n",
       "2                        Shake it before you bake it   \n",
       "3                     Not what the picture describes   \n",
       "4                  What a ripe off - GIVE ME A BREAK   \n",
       "\n",
       "                                                body rating helpful_user_num  \\\n",
       "0  The herb kit that came with my Aerogarden was ...      2               15   \n",
       "1  I originally bought this just because it was c...      5               19   \n",
       "2  If you do it in reverse (bake before shaking),...      2                2   \n",
       "3  I bought this steak for my father in law for C...      2                7   \n",
       "4  Sorry but I had these noodles and they are no ...      2               10   \n",
       "\n",
       "  total_user_num  \n",
       "0             17  \n",
       "1             19  \n",
       "2             13  \n",
       "3             14  \n",
       "4             34  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['title', 'body', 'rating', 'helpful_user_num', 'total_user_num'])\n",
    "#for url in total_herf:\n",
    "for url in lines:\n",
    "    #find rating\n",
    "    html = urlopen(url).read().decode()\n",
    "    soup = BeautifulSoup(html, features='lxml')\n",
    "    rating = soup.find_all(\"img\", {\"alt\": re.compile('[0-9]')})\n",
    "\n",
    "    # extract rating from each page\n",
    "    # extract number n from \"n-star\" term\n",
    "    #rating = [l[\"alt\"] for l in rating]\n",
    "    rating = [re.findall('[0-9]+', line[\"alt\"]) for line in rating]\n",
    "    rating = [int(item) for num in rating for item in num]\n",
    "\n",
    "    # extract rating \n",
    "    title_class = soup.find_all('h5')\n",
    "    title = [(item.get_text().replace(u'\\xa0', u'')) for item in title_class]\n",
    "\n",
    "    #extract body\n",
    "    body_class = soup.find_all(\"p\", {\"class\": \"review-body\"})\n",
    "    body = [(item.get_text().replace(u'\\xa0', u'')) for item in body_class]\n",
    "\n",
    "    #extract helpful record to a pair of number\n",
    "    helpful_class = soup.find_all(string=re.compile(\"\\d users found this review helpful$\"))\n",
    "    helpful = [re.findall('[0-9]+', line) for line in helpful_class]\n",
    "    helpful = [[int(i) for i in line] for line in helpful]\n",
    "    helpful_user = []\n",
    "    total_user = []\n",
    "    for line in helpful:\n",
    "        helpful_user.append(line[0])\n",
    "        total_user.append(line[1])\n",
    "\n",
    "    df1 = pd.DataFrame({\"title\":title, \n",
    "    \"body\":body, \"rating\":rating, \"helpful_user_num\":helpful_user, \"total_user_num\":total_user})\n",
    "    df = pd.concat([df, df1])\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dump the dataframe to csv file to store the unique dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('dataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('comp47670')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "934230a5e25259e6f838a3b0be03529e5a61917a11adaf40705993f4a1dc1d82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
